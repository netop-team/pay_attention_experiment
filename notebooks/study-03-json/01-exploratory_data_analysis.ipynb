{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel, \\\n",
    "  BitsAndBytesConfig, GPTQConfig\n",
    "import os\n",
    "\n",
    "while \"notebooks\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from langdetect import detect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset\n",
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "from bert_score import BERTScorer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from copy import deepcopy\n",
    "from openai import OpenAI\n",
    "from babilong.babilong.prompts import DEFAULT_PROMPTS, DEFAULT_TEMPLATE, get_formatted_input\n",
    "from babilong.babilong.babilong_utils import compare_answers\n",
    "\n",
    "from src.utils import rotate_half, apply_rotary_pos_emb, repeat_kv, \\\n",
    "    get_context_length, get_generated_text, FileReader, is_text_in_language, rolling_mean\n",
    "\n",
    "import json\n",
    "\n",
    "from src.attention_saver import Mistral7BAttentionSaver\n",
    "from src.influence import Influence\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing models and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986ad793730b43cb9b071300d8a5b4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    cache_dir = \"/Data\"    \n",
    ")\n",
    "\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    quantization_config = quantization_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"eager\",\n",
    "    cache_dir = \"/Data\"\n",
    ")\n",
    "\n",
    "\n",
    "model_name = base_model.config._name_or_path.split(\"/\")[1]\n",
    "\n",
    "model = Mistral7BAttentionSaver(\n",
    "    base_model,\n",
    "    tokenizer,\n",
    "    delta_attention=0,\n",
    "    should_save_params= False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3c7fe15ce440c4a5d4790c21efddfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2c1bc05c03458eb4ac8c5b79990d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/63.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c632e4a631de4c58833b195ebd82749f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/135k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49d42f3272f473ca5072aa3987bbae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating multi_turn split:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eef4fefdc71496baf557c2accdb01fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating single_turn split:   0%|          | 0/112 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = load_dataset(\"fireworks-ai/function-calling-eval-dataset-v0\", cache_dir = \"/Data\")\\\n",
    "    ['single_turn']\\\n",
    "    .to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3135\n",
       "1      3173\n",
       "2      3157\n",
       "3      3144\n",
       "4      3152\n",
       "       ... \n",
       "107    3174\n",
       "108    3147\n",
       "109    3140\n",
       "110    3148\n",
       "111    3165\n",
       "Name: prompt, Length: 112, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = df['prompt'].apply(lambda x: get_context_length(x[0]['content'], tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['instruction'] = df['prompt'].apply(lambda x: x[0]['content'])\n",
    "df['text'] = df['prompt'].apply(lambda x : x[1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>schema</th>\n",
       "      <th>instruction</th>\n",
       "      <th>text</th>\n",
       "      <th>json_schema</th>\n",
       "      <th>context_length</th>\n",
       "      <th>json_context_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "      <td>{\"ssid\": \"OfficeNetSecure\", \"securityProtocol\"...</td>\n",
       "      <td>{\"title\": \"WirelessAccessPoint\", \"type\": \"obje...</td>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>I'm currently configuring a wireless access po...</td>\n",
       "      <td>\\n{'title': 'WirelessAccessPoint', 'type': 'ob...</td>\n",
       "      <td>248</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "      <td>{\"/\": {\"device\": \"/dev/sda1\", \"mount_point\": \"...</td>\n",
       "      <td>{\"$id\": \"https://example.com/fstab\", \"$schema\"...</td>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>I need to create a JSON representation of the ...</td>\n",
       "      <td>\\n{'title': 'WirelessAccessPoint', 'type': 'ob...</td>\n",
       "      <td>434</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "      <td>{\"campaignID\": \"CAMP123456\", \"productID\": \"PRO...</td>\n",
       "      <td>{\"title\": \"PromotionalCampaign\", \"type\": \"obje...</td>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>I'm organizing a promotional campaign for our ...</td>\n",
       "      <td>\\n{'title': 'WirelessAccessPoint', 'type': 'ob...</td>\n",
       "      <td>300</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "      <td>{\"reservationID\": \"AH-158394\", \"guestName\": \"A...</td>\n",
       "      <td>{\"title\": \"RestaurantReservation\", \"type\": \"ob...</td>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>I'd like to make a reservation at The Gourmet ...</td>\n",
       "      <td>\\n{'title': 'WirelessAccessPoint', 'type': 'ob...</td>\n",
       "      <td>285</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "      <td>{\"HomeImprovement\": {\"room_interest\": \"living ...</td>\n",
       "      <td>{\"type\": \"object\", \"properties\": {\"HomeImprove...</td>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>I'm looking to spruce up my living room within...</td>\n",
       "      <td>\\n{'title': 'WirelessAccessPoint', 'type': 'ob...</td>\n",
       "      <td>267</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  [{'content': 'You are a helpful assistant that...   \n",
       "1  [{'content': 'You are a helpful assistant that...   \n",
       "2  [{'content': 'You are a helpful assistant that...   \n",
       "3  [{'content': 'You are a helpful assistant that...   \n",
       "4  [{'content': 'You are a helpful assistant that...   \n",
       "\n",
       "                                          completion  \\\n",
       "0  {\"ssid\": \"OfficeNetSecure\", \"securityProtocol\"...   \n",
       "1  {\"/\": {\"device\": \"/dev/sda1\", \"mount_point\": \"...   \n",
       "2  {\"campaignID\": \"CAMP123456\", \"productID\": \"PRO...   \n",
       "3  {\"reservationID\": \"AH-158394\", \"guestName\": \"A...   \n",
       "4  {\"HomeImprovement\": {\"room_interest\": \"living ...   \n",
       "\n",
       "                                              schema  \\\n",
       "0  {\"title\": \"WirelessAccessPoint\", \"type\": \"obje...   \n",
       "1  {\"$id\": \"https://example.com/fstab\", \"$schema\"...   \n",
       "2  {\"title\": \"PromotionalCampaign\", \"type\": \"obje...   \n",
       "3  {\"title\": \"RestaurantReservation\", \"type\": \"ob...   \n",
       "4  {\"type\": \"object\", \"properties\": {\"HomeImprove...   \n",
       "\n",
       "                                         instruction  \\\n",
       "0  You are a helpful assistant that answers in JS...   \n",
       "1  You are a helpful assistant that answers in JS...   \n",
       "2  You are a helpful assistant that answers in JS...   \n",
       "3  You are a helpful assistant that answers in JS...   \n",
       "4  You are a helpful assistant that answers in JS...   \n",
       "\n",
       "                                                text  \\\n",
       "0  I'm currently configuring a wireless access po...   \n",
       "1  I need to create a JSON representation of the ...   \n",
       "2  I'm organizing a promotional campaign for our ...   \n",
       "3  I'd like to make a reservation at The Gourmet ...   \n",
       "4  I'm looking to spruce up my living room within...   \n",
       "\n",
       "                                         json_schema  context_length  \\\n",
       "0  \\n{'title': 'WirelessAccessPoint', 'type': 'ob...             248   \n",
       "1  \\n{'title': 'WirelessAccessPoint', 'type': 'ob...             434   \n",
       "2  \\n{'title': 'WirelessAccessPoint', 'type': 'ob...             300   \n",
       "3  \\n{'title': 'WirelessAccessPoint', 'type': 'ob...             285   \n",
       "4  \\n{'title': 'WirelessAccessPoint', 'type': 'ob...             267   \n",
       "\n",
       "   json_context_length  \n",
       "0                   44  \n",
       "1                  195  \n",
       "2                   84  \n",
       "3                   81  \n",
       "4                  123  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['json_schema'] = df['instruction'][0]\\\n",
    "    .split(\"<schema>\")[1]\\\n",
    "    .split(\"</schema>\")[0]\n",
    "\n",
    "\n",
    "df['json_context_length'] = df['completion'].progress_apply(get_context_length, tokenizer = tokenizer)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant that answers in JSON. Here's the json schema you must adhere to:\n",
      "\n",
      "<schema>\n",
      "{schema}\n",
      "</schema>\n",
      "\n",
      "{noise}\n",
      "\n",
      "{content}\n",
      "\n",
      "Do not output anything else than the JSON.\n"
     ]
    }
   ],
   "source": [
    "TEMPLATE = \"You are a helpful assistant that answers in JSON. Here's the json schema you must adhere to:\\n\\n<schema>\\n{schema}\\n</schema>\\n\\n{noise}\\n\\n{content}\\n\\nDo not output anything else than the JSON.\"\n",
    "print(TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:09<00:00, 1044.55it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "noise_df = load_dataset(\n",
    "    \"stas/openwebtext-10k\", cache_dir=\"/Data\"\n",
    ")['train'].to_pandas()\n",
    "\n",
    "noise_df['context_length'] = noise_df['text']\\\n",
    "    .progress_apply(get_context_length, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = ['']\n",
    "for n in range(7):\n",
    "    noise = noise_df.query(f\"context_length >= 500*{n} & context_length < 500*{n+1}\")\\\n",
    "        .sample(1)\\\n",
    "        .text\\\n",
    "        .item()\n",
    "    \n",
    "    noises.append(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = []\n",
    "\n",
    "for noise in noises:\n",
    "    this_df = deepcopy(df)\n",
    "    this_df['prompt'] = this_df.apply(\n",
    "        lambda row: TEMPLATE.format(\n",
    "            schema = row['json_schema'],\n",
    "            noise = noise,\n",
    "            content = row['text']\n",
    "        ),\n",
    "        axis = 1\n",
    "    )\n",
    "\n",
    "    all_df.append(this_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/800 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:02<00:00, 327.99it/s] \n"
     ]
    }
   ],
   "source": [
    "augmented_df = pd.concat(all_df)\\\n",
    "    .reset_index(drop = True)\n",
    "\n",
    "\n",
    "augmented_df['context_length'] = augmented_df['prompt']\\\n",
    "    .progress_apply(get_context_length, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1176.45it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 5229.48it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize= (10,5))\n",
    "\n",
    "sns.histplot(augmented_df['context_length'], ax = ax1)\n",
    "sns.histplot(augmented_df['json_context_length'], ax = ax2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'content': \"You are a helpful assistant that answers in JSON. Here's the json schema you must adhere to:\\n<schema>\\n{'title': 'WirelessAccessPoint', 'type': 'object', 'properties': {'ssid': {'title': 'SSID', 'type': 'string'}, 'securityProtocol': {'title': 'SecurityProtocol', 'type': 'string'}, 'bandwidth': {'title': 'Bandwidth', 'type': 'string'}}, 'required': ['ssid', 'securityProtocol', 'bandwidth']}\\n</schema>\\n\", 'role': 'system'},\n",
       "       {'content': \"I'm currently configuring a wireless access point for our office network and I need to generate a JSON object that accurately represents its settings. The access point's SSID should be 'OfficeNetSecure', it uses WPA2-Enterprise as its security protocol, and it's capable of a bandwidth of up to 1300 Mbps on the 5 GHz band. This JSON object will be used to document our network configurations and to automate the setup process for additional access points in the future. Please provide a JSON object that includes these details.\", 'role': 'user'}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt                 You are a helpful assistant that answers in JS...\n",
       "completion             {\"statementID\": \"GDB-4512\", \"customerID\": \"CUS...\n",
       "schema                 {\"title\": \"AccountStatement\", \"type\": \"object\"...\n",
       "instruction            You are a helpful assistant that answers in JS...\n",
       "text                   I need to create a digital record of my recent...\n",
       "json_schema            \\n{'title': 'WirelessAccessPoint', 'type': 'ob...\n",
       "context_length                                                      3844\n",
       "json_context_length                                                  295\n",
       "Name: 732, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"data/study-04-json/01/checkpoints/delta={delta}.parquet\"\n",
    "base_path = \"data/study-04-json/01/delta={delta}.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt                 You are a helpful assistant that answers in JS...\n",
       "completion             {\"current_location\": \"Boulder, Colorado\", \"pre...\n",
       "schema                 {\"WeatherUpdates\": {\"type\": \"object\", \"propert...\n",
       "instruction            You are a helpful assistant that answers in JS...\n",
       "text                   I'm planning to go hiking this weekend and I n...\n",
       "json_schema            \\n{'title': 'WirelessAccessPoint', 'type': 'ob...\n",
       "context_length                                                      3813\n",
       "json_context_length                                                  197\n",
       "Name: 772, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA_ATTENTION = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            text index = 780,\n",
      "            context length = 3817,\n",
      "            last generated text = \n",
      " {\n",
      "\"chemical\\_id\": \"GC2022-7705\",\n",
      "\"name\": \"Lignin-derived polymeric compound\",\n",
      "\"type\": \"Polymer\",\n",
      "\"applications\": [\n",
      "\"Energy storage\",\n",
      "\"Targeted drug delivery\",\n",
      "\"Efficient adsorption\",\n",
      "\"Catalysis\",\n",
      "\"Functional packaging\",\n",
      "\"Slow-release fertilizers\"\n",
      "]\n",
      "}</s>\n",
      "            correct = False\n",
      "            \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 83\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124m        text index = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     80\u001b[0m     )\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 83\u001b[0m     generated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# suppress_tokens = [endline_token, tab_token, double_backspace_token, backspace_token, triple_backspace_token],\u001b[39;49;00m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# forced_decoder_ids = [[0, left_brace_token]],\u001b[39;49;00m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m decoded \u001b[38;5;241m=\u001b[39m (tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(generated_ids)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     92\u001b[0m target \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompletion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/src/attention_saver.py:48\u001b[0m, in \u001b[0;36mMistral7BAttentionSaver.generate\u001b[0;34m(self, token_ids, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, token_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/transformers/generation/utils.py:1909\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1901\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1902\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1903\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1904\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1905\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1906\u001b[0m     )\n\u001b[1;32m   1908\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1909\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1910\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1923\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1924\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   1925\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1926\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/transformers/generation/utils.py:2646\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2643\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2645\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2646\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2647\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2649\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2650\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2654\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:1195\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1192\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1195\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1208\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1209\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:971\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    960\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    961\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    962\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    968\u001b[0m         cache_position,\n\u001b[1;32m    969\u001b[0m     )\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 971\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:727\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    725\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    726\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 727\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    730\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:171\u001b[0m, in \u001b[0;36mMistralMLP.forward\u001b[0;34m(self, hidden_state)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_state):\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(hidden_state)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:470\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    467\u001b[0m bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[1;32m    468\u001b[0m out \u001b[38;5;241m=\u001b[39m bnb\u001b[38;5;241m.\u001b[39mmatmul_4bit(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mt(), bias\u001b[38;5;241m=\u001b[39mbias, quant_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mquant_state)\n\u001b[0;32m--> 470\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# endline_token = 13\n",
    "# tab_token = 12\n",
    "# double_backspace_token = 259\n",
    "# triple_backspace_token = 2287\n",
    "# backspace_token = 28705\n",
    "# quotation_mark_token = 345\n",
    "# left_brace_token = 371\n",
    "\n",
    "decoded = None\n",
    "generated_text = {}\n",
    "\n",
    "for i, (idx, row) in enumerate(augmented_df.sort_values(\"context_length\", ascending= False).iterrows()):\n",
    "    \n",
    "    text = row['prompt']\n",
    "    message = [{\"role\": \"user\", \"content\": text}]\n",
    "    schema = row['json_schema'] \n",
    "    \"<schema>\\n\" \"\\n</schema>\"\n",
    "    template = tokenizer.apply_chat_template(message, tokenize=False)\n",
    "    \n",
    "    splits = template.split(\"<schema>\\n\" + schema +\"\\n</schema>\")\n",
    "    initial_prompt = splits[0]\n",
    "    context = splits[1]\n",
    "\n",
    "    assert (hash(initial_prompt+\"<schema>\\n\"+schema+\"\\n</schema>\"+context) == hash(template)), \"Error in spliting strings. Initial and final string does not match\"\n",
    "\n",
    "    initial_tokens = tokenizer.encode(initial_prompt, return_tensors='pt')\n",
    "    open_tag_tokens = tokenizer.encode(\"<schema>\\n\", return_tensors='pt')\n",
    "    schema_tokens = tokenizer.encode(schema, return_tensors='pt')\n",
    "    close_tag_tokens = tokenizer.encode(\"\\n</schema>\", return_tensors='pt')\n",
    "    context_tokens = tokenizer.encode(context, return_tensors='pt')\n",
    "\n",
    "    start_idx = initial_tokens.size(1) + open_tag_tokens.size(1) - 1\n",
    "    end_idx = start_idx + schema_tokens.size(1) - 1\n",
    "\n",
    "    model.set_reference_tokens(start_idx, end_idx)\n",
    "    \n",
    "    tokens = torch.concat([\n",
    "        initial_tokens.squeeze(), \n",
    "        open_tag_tokens.squeeze()[1:],\n",
    "        schema_tokens.squeeze()[1:],\n",
    "        close_tag_tokens.squeeze()[1:],\n",
    "        context_tokens.squeeze()[1:]\n",
    "    ]).unsqueeze(0)\n",
    "\n",
    "    q = tokenizer.decode(tokens.squeeze()[start_idx: end_idx])\n",
    "\n",
    "    assert schema in q, \"Error in tokenization. Not giving attention to correct tokens\"\n",
    "\n",
    "    tokens2 = tokenizer(template, return_tensors='pt')\n",
    "\n",
    "    assert (abs(tokens.shape[1] - tokens2['input_ids'].shape[1]) <=5 ), \"Error in tokenization. Tokens do not match\"\n",
    "\n",
    "    clear_output()\n",
    "\n",
    "    if decoded is not None:\n",
    "        json_obj = decoded.split(\"[/INST]\")[1]\\\n",
    "            .replace(\"\\n\", '')\\\n",
    "            .replace('</s>', '')\\\n",
    "            .replace('\\r', '')\\\n",
    "            .replace('          ', '')\\\n",
    "            .replace(\"\\\\\", '')\n",
    "        \n",
    "        try:\n",
    "            json_obj   = json.loads(json_obj)\n",
    "            target = json.loads(target)\n",
    "            \n",
    "            is_equal = json_obj == target\n",
    "\n",
    "        except:\n",
    "            is_equal = 'error in json loading'\n",
    "\n",
    "        print(\n",
    "            f'''\n",
    "            text index = {idx},\n",
    "            context length = {row['context_length']},\n",
    "            last generated text = \n",
    "{decoded.split('[/INST]')[1]}\n",
    "            correct = {is_equal}\n",
    "            '''\n",
    "        )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            tokens, \n",
    "            max_new_tokens = 1_000, \n",
    "            # suppress_tokens = [endline_token, tab_token, double_backspace_token, backspace_token, triple_backspace_token],\n",
    "            # forced_decoder_ids = [[0, left_brace_token]],\n",
    "            do_sample = False,\n",
    "        )\n",
    "\n",
    "    decoded = (tokenizer.batch_decode(generated_ids)[0])\n",
    "    target = row['completion']\n",
    "    generated_text[idx] = decoded\n",
    "\n",
    "    if i % 100  == 0:\n",
    "        checkpoint_file = checkpoint_path.format(\n",
    "            delta = DELTA_ATTENTION\n",
    "        )\n",
    "        checkpoint_file = Path(checkpoint_file)\n",
    "        checkpoint_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        augmented_df['generated_text'] = pd.Series(generated_text)\n",
    "        augmented_df.to_parquet(checkpoint_file)\n",
    "\n",
    "outfile = base_path.format(\n",
    "    delta = DELTA_ATTENTION\n",
    ")\n",
    "\n",
    "outfile.parent.mkidr(parents = True, exist_ok = True)\n",
    "augmented_df['generated_text'] = pd.Series(generated_text)\n",
    "augmented_df.to_parquet(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df['generated_text'] = pd.Series(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>schema</th>\n",
       "      <th>instruction</th>\n",
       "      <th>text</th>\n",
       "      <th>json_schema</th>\n",
       "      <th>context_length</th>\n",
       "      <th>json_context_length</th>\n",
       "      <th>generated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>{\"ssid\": \"OfficeNetSecure\", \"securityProtocol\"...</td>\n",
       "      <td>{\"title\": \"WirelessAccessPoint\", \"type\": \"obje...</td>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>I'm currently configuring a wireless access po...</td>\n",
       "      <td>\\n{'title': 'WirelessAccessPoint', 'type': 'ob...</td>\n",
       "      <td>265</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>{\"/\": {\"device\": \"/dev/sda1\", \"mount_point\": \"...</td>\n",
       "      <td>{\"$id\": \"https://example.com/fstab\", \"$schema\"...</td>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>I need to create a JSON representation of the ...</td>\n",
       "      <td>\\n{'title': 'WirelessAccessPoint', 'type': 'ob...</td>\n",
       "      <td>220</td>\n",
       "      <td>195</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>{\"campaignID\": \"CAMP123456\", \"productID\": \"PRO...</td>\n",
       "      <td>{\"title\": \"PromotionalCampaign\", \"type\": \"obje...</td>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>I'm organizing a promotional campaign for our ...</td>\n",
       "      <td>\\n{'title': 'WirelessAccessPoint', 'type': 'ob...</td>\n",
       "      <td>262</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>{\"reservationID\": \"AH-158394\", \"guestName\": \"A...</td>\n",
       "      <td>{\"title\": \"RestaurantReservation\", \"type\": \"ob...</td>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>I'd like to make a reservation at The Gourmet ...</td>\n",
       "      <td>\\n{'title': 'WirelessAccessPoint', 'type': 'ob...</td>\n",
       "      <td>257</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>{\"HomeImprovement\": {\"room_interest\": \"living ...</td>\n",
       "      <td>{\"type\": \"object\", \"properties\": {\"HomeImprove...</td>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>I'm looking to spruce up my living room within...</td>\n",
       "      <td>\\n{'title': 'WirelessAccessPoint', 'type': 'ob...</td>\n",
       "      <td>266</td>\n",
       "      <td>123</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>{\"portName\": \"Harbor Bay Port\", \"date\": \"2023-...</td>\n",
       "      <td>{\"title\": \"DockingTimeQuery\", \"type\": \"object\"...</td>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>I need to schedule a shipment arrival at a mar...</td>\n",
       "      <td>\\n{'title': 'WirelessAccessPoint', 'type': 'ob...</td>\n",
       "      <td>3711</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>{\"productName\": \"Organic Red Apples\", \"SKU\": \"...</td>\n",
       "      <td>{\"properties\": {\"productName\": {\"title\": \"Prod...</td>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>I am currently managing the inventory for our ...</td>\n",
       "      <td>\\n{'title': 'WirelessAccessPoint', 'type': 'ob...</td>\n",
       "      <td>3717</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>{\"diesel\": {\"fuelType\": \"Diesel\", \"quantityInS...</td>\n",
       "      <td>{\"FuelInventoryReport\": {\"title\": \"FuelInvento...</td>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>I am currently managing the inventory for our ...</td>\n",
       "      <td>\\n{'title': 'WirelessAccessPoint', 'type': 'ob...</td>\n",
       "      <td>3816</td>\n",
       "      <td>127</td>\n",
       "      <td>&lt;s&gt;&lt;s&gt; [INST] You are a helpful assistant that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>{\"shipmentID\": \"SH12345\", \"componentID\": \"COMP...</td>\n",
       "      <td>{\"title\": \"ShipmentStatusTracker\", \"type\": \"ob...</td>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>Hello, I am currently managing logistics for o...</td>\n",
       "      <td>\\n{'title': 'WirelessAccessPoint', 'type': 'ob...</td>\n",
       "      <td>3800</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>{\"productID\": \"MOIST-12345\", \"stockQuantity\": ...</td>\n",
       "      <td>{\"title\": \"InventoryTracking\", \"type\": \"object...</td>\n",
       "      <td>You are a helpful assistant that answers in JS...</td>\n",
       "      <td>I'm currently managing a local store that sell...</td>\n",
       "      <td>\\n{'title': 'WirelessAccessPoint', 'type': 'ob...</td>\n",
       "      <td>3771</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "0    You are a helpful assistant that answers in JS...   \n",
       "1    You are a helpful assistant that answers in JS...   \n",
       "2    You are a helpful assistant that answers in JS...   \n",
       "3    You are a helpful assistant that answers in JS...   \n",
       "4    You are a helpful assistant that answers in JS...   \n",
       "..                                                 ...   \n",
       "795  You are a helpful assistant that answers in JS...   \n",
       "796  You are a helpful assistant that answers in JS...   \n",
       "797  You are a helpful assistant that answers in JS...   \n",
       "798  You are a helpful assistant that answers in JS...   \n",
       "799  You are a helpful assistant that answers in JS...   \n",
       "\n",
       "                                            completion  \\\n",
       "0    {\"ssid\": \"OfficeNetSecure\", \"securityProtocol\"...   \n",
       "1    {\"/\": {\"device\": \"/dev/sda1\", \"mount_point\": \"...   \n",
       "2    {\"campaignID\": \"CAMP123456\", \"productID\": \"PRO...   \n",
       "3    {\"reservationID\": \"AH-158394\", \"guestName\": \"A...   \n",
       "4    {\"HomeImprovement\": {\"room_interest\": \"living ...   \n",
       "..                                                 ...   \n",
       "795  {\"portName\": \"Harbor Bay Port\", \"date\": \"2023-...   \n",
       "796  {\"productName\": \"Organic Red Apples\", \"SKU\": \"...   \n",
       "797  {\"diesel\": {\"fuelType\": \"Diesel\", \"quantityInS...   \n",
       "798  {\"shipmentID\": \"SH12345\", \"componentID\": \"COMP...   \n",
       "799  {\"productID\": \"MOIST-12345\", \"stockQuantity\": ...   \n",
       "\n",
       "                                                schema  \\\n",
       "0    {\"title\": \"WirelessAccessPoint\", \"type\": \"obje...   \n",
       "1    {\"$id\": \"https://example.com/fstab\", \"$schema\"...   \n",
       "2    {\"title\": \"PromotionalCampaign\", \"type\": \"obje...   \n",
       "3    {\"title\": \"RestaurantReservation\", \"type\": \"ob...   \n",
       "4    {\"type\": \"object\", \"properties\": {\"HomeImprove...   \n",
       "..                                                 ...   \n",
       "795  {\"title\": \"DockingTimeQuery\", \"type\": \"object\"...   \n",
       "796  {\"properties\": {\"productName\": {\"title\": \"Prod...   \n",
       "797  {\"FuelInventoryReport\": {\"title\": \"FuelInvento...   \n",
       "798  {\"title\": \"ShipmentStatusTracker\", \"type\": \"ob...   \n",
       "799  {\"title\": \"InventoryTracking\", \"type\": \"object...   \n",
       "\n",
       "                                           instruction  \\\n",
       "0    You are a helpful assistant that answers in JS...   \n",
       "1    You are a helpful assistant that answers in JS...   \n",
       "2    You are a helpful assistant that answers in JS...   \n",
       "3    You are a helpful assistant that answers in JS...   \n",
       "4    You are a helpful assistant that answers in JS...   \n",
       "..                                                 ...   \n",
       "795  You are a helpful assistant that answers in JS...   \n",
       "796  You are a helpful assistant that answers in JS...   \n",
       "797  You are a helpful assistant that answers in JS...   \n",
       "798  You are a helpful assistant that answers in JS...   \n",
       "799  You are a helpful assistant that answers in JS...   \n",
       "\n",
       "                                                  text  \\\n",
       "0    I'm currently configuring a wireless access po...   \n",
       "1    I need to create a JSON representation of the ...   \n",
       "2    I'm organizing a promotional campaign for our ...   \n",
       "3    I'd like to make a reservation at The Gourmet ...   \n",
       "4    I'm looking to spruce up my living room within...   \n",
       "..                                                 ...   \n",
       "795  I need to schedule a shipment arrival at a mar...   \n",
       "796  I am currently managing the inventory for our ...   \n",
       "797  I am currently managing the inventory for our ...   \n",
       "798  Hello, I am currently managing logistics for o...   \n",
       "799  I'm currently managing a local store that sell...   \n",
       "\n",
       "                                           json_schema  context_length  \\\n",
       "0    \\n{'title': 'WirelessAccessPoint', 'type': 'ob...             265   \n",
       "1    \\n{'title': 'WirelessAccessPoint', 'type': 'ob...             220   \n",
       "2    \\n{'title': 'WirelessAccessPoint', 'type': 'ob...             262   \n",
       "3    \\n{'title': 'WirelessAccessPoint', 'type': 'ob...             257   \n",
       "4    \\n{'title': 'WirelessAccessPoint', 'type': 'ob...             266   \n",
       "..                                                 ...             ...   \n",
       "795  \\n{'title': 'WirelessAccessPoint', 'type': 'ob...            3711   \n",
       "796  \\n{'title': 'WirelessAccessPoint', 'type': 'ob...            3717   \n",
       "797  \\n{'title': 'WirelessAccessPoint', 'type': 'ob...            3816   \n",
       "798  \\n{'title': 'WirelessAccessPoint', 'type': 'ob...            3800   \n",
       "799  \\n{'title': 'WirelessAccessPoint', 'type': 'ob...            3771   \n",
       "\n",
       "     json_context_length                                     generated_text  \n",
       "0                     44                                                NaN  \n",
       "1                    195                                                NaN  \n",
       "2                     84                                                NaN  \n",
       "3                     81                                                NaN  \n",
       "4                    123                                                NaN  \n",
       "..                   ...                                                ...  \n",
       "795                   81                                                NaN  \n",
       "796                   54                                                NaN  \n",
       "797                  127  <s><s> [INST] You are a helpful assistant that...  \n",
       "798                   58                                                NaN  \n",
       "799                   59                                                NaN  \n",
       "\n",
       "[800 rows x 9 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"diesel\": {\"fuelType\": \"Diesel\", \"quantityInStock\": 5000, \"reorderLevel\": 1500}, \"gasoline\": {\"fuelType\": \"Gasoline\", \"quantityInStock\": 7500, \"reorderLevel\": 2000}, \"aviationFuel\": {\"fuelType\": \"Aviation Fuel\", \"quantityInStock\": 2500, \"reorderLevel\": 1000}}'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' {\"distributor\\\\_id\": \"DIST12345X\",\"company\\\\_name\": \"Gadgets and Widgets Co.\",\"phone\\\\_number\": \"+1-555-0199\",\"email\\\\_address\": \"contact@gadgets-widgets.com\",\"physical\\\\_address\": \"1234 Innovation Way, Tech City, 98765\",\"categories\": [\"Electronics\", \"Home Appliances\", \"Office Supplies\"]}'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(generated_text).to_pickle(\"data/study-04-json/delta=0.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['generated_text'] = pd.Series(generated_text)\\\n",
    "    .apply(lambda x: x.split('[/INST]')[1])\\\n",
    "    .apply(\n",
    "        lambda x:   x.replace(\"\\n\", '')\\\n",
    "                     .replace('</s>', '')\\\n",
    "                     .replace('\\r', '')\\\n",
    "                     .replace('          ', '')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(x):\n",
    "    try :\n",
    "        return json.loads(x)\n",
    "    \n",
    "    except : \n",
    "        return 0\n",
    "\n",
    "df['json'] = df['generated_text'].apply(get_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['completion'] = df['completion'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_json(row):\n",
    "    target_json = row['completion']\n",
    "    generated_json = row['json']\n",
    "    \n",
    "    if generated_json == 0:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    \n",
    "    n_keys = len(target_json)\n",
    "    acc = 0\n",
    "\n",
    "    for key in target_json.keys():\n",
    "        if not key in generated_json:\n",
    "            continue\n",
    "\n",
    "        if generated_json[key] == target_json[key]:\n",
    "            acc += 1\n",
    "\n",
    "    return acc/max(n_keys, len(generated_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7968333333333334"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(score_json, axis = 1)\\\n",
    "    .mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f5a9de632d0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(df.apply(score_json, axis = 1), stat = 'probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['completion'].iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
