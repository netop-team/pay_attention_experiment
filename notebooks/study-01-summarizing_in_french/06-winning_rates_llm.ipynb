{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel, \\\n",
    "  BitsAndBytesConfig, GPTQConfig\n",
    "import os\n",
    "\n",
    "while \"notebooks\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "import scienceplots\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from langdetect import detect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset\n",
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "from bert_score import BERTScorer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from copy import deepcopy\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "from src.utils import rotate_half, apply_rotary_pos_emb, repeat_kv, \\\n",
    "    get_context_length, get_generated_text, FileReader, is_text_in_language, rolling_mean,\\\n",
    "    get_context_length\n",
    "\n",
    "from src.attention_saver import Mistral7BAttentionSaver\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# plt.rc('font', family='serif')\n",
    "# plt.rc('xtick', labelsize='x-small')\n",
    "# plt.rc('ytick', labelsize='x-small')\n",
    "plt.style.use(['science','no-latex'])\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    cache_dir = \"/Data\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "df = load_dataset(\"stas/openwebtext-10k\", cache_dir= \"/Data\")['train'].to_pandas()\n",
    "df[\"text_len\"] = df[\"text\"].apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:19<00:00, 504.12it/s]\n"
     ]
    }
   ],
   "source": [
    "base_instruction = \"Summarize in french\"\n",
    "df[\"context_length\"] = (base_instruction + \" \\n\" + df[\"text\"])\\\n",
    "    .progress_apply(get_context_length, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'data/complete_study_200_tokens/checkpoints/all_layers_generated_delta=0.0.pkl'\n",
      "Exception raised while analysing the text  21 =85 9/5=4 1 2 2 0 0 0 0 2 2 1 2 2 0 0 4 9 9 9 0 0 0 0 4 9 9 9 0 0 0 0 4 9 9 9 0 0 0 0 3 9 9 9 0 0 0 0 3 9 9 9 0 0 0 0 3 9 9 9 0 0 0 0 3 9 9 9 0 0 0 0 3 9 9 9 0 0 0 0 3 9 9 9 0 0 0 0 4 9 9 9 0 0 0 0\n",
      "Exception raised while analysing the text  1\n",
      "2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 7\n",
      "Exception raised while analysing the text  1\n",
      "2\n",
      "3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 7\n",
      "Exception raised while analysing the text  ·ñ∫·ñ∑ ·ã®·àµ·âµ·àµ·âµ ·àµ·âµ·àµ·âµ ·ã®·äï·àï·âµ·äï·àù ·ã®·à≠·äï·äï·àù ·àµ·âµ·àµ·âµ·àµ·âµ ·ã®·àµ·âµ·àµ·âµ ·àµ·âµ·àµ·âµ ·ã®·àµ·âµ·àµ·âµ ·àµ·âµ·àµ·âµ ·ã®·äï·äï·àù ·ã®·äï·àï·äï·àµ·âµ·äï·àù ·ã®·àµ·âµ·àµ·âµ ·ã®·äï·àµ·âµ·äï·àù ·ã®·äï·äï·àù ·ã®·àµ·âµ·àµ·âµ ·ã®·äï·àµ·âµ·äï·àù ·ã®·äï·àµ·âµ·äï·àù ·ã®·äï·àµ·âµ·äï·àù ·ã®·äï·äï·äï·àù ·ã®·äï·àµ·âµ·äï·àù ·ã®·äï·àµ·âµ·äï·àù ·ã®·äï·àµ·âµ·äï·àù ·ã®·äï·àµ·âµ·äï·àù ·ã®·äï·àµ·âµ·äï·àù ·ã®·äï·àµ·âµ·äï·àù ·ã®·äï·àµ·âµ·äï·àù ·ã®·äï·àµ·âµ·äï·àù ·ã®·äï·àµ·âµ·äï·àù ·ã®·äï·àµ·âµ·äï·àù \n",
      "Exception raised while analysing the text  ¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°¬°\n",
      "[Errno 2] No such file or directory: 'data/complete_study_200_tokens/checkpoints/none_layers_generated_delta=0.5.pkl'\n",
      "Exception raised while analysing the text  =78 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 \n",
      "[Errno 2] No such file or directory: 'data/complete_study_200_tokens/checkpoints/none_layers_generated_delta=1.0.pkl'\n",
      "[Errno 2] No such file or directory: 'data/complete_study_200_tokens/checkpoints/none_layers_generated_delta=2.0.pkl'\n",
      "Exception raised while analysing the text  271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320\n",
      "Exception raised while analysing the text  1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,\n",
      "61,62,63,64,65,66,67,68,69,\n",
      "Exception raised while analysing the text  3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3\n",
      "Exception raised while analysing the text  ‚à´‚ãØ‚à´</s>\n",
      "Exception raised while analysing the text  üé¨üé¨üé¨ üé¨üé¨üé¨ üé¨üé¨üé¨üé¨ üé¨üé¨üé¨üé¨ üé¨üé¨üé¨ üé¨üé¨üé¨üé¨ üé¨üé¨üé¨üé¨ üé¨üé¨üé¨üé¨ üé¨üé¨üé¨üé¨ üé¨üé¨üé¨ üé¨üé¨üé¨üé¨üé¨ üé¨üé¨üé¨üé¨üé¨üé¨\n",
      "[Errno 2] No such file or directory: 'data/complete_study_200_tokens/checkpoints/none_layers_generated_delta=5.0.pkl'\n"
     ]
    }
   ],
   "source": [
    "base_path = \"data/complete_study_200_tokens/checkpoints/\"\n",
    "all_results = []\n",
    "for delta_attention in [0., 0.5, 1., 2.0, 5.0]:\n",
    "    for all_layers in [\"all\", \"none\"]:\n",
    "        path = os.path.join(\n",
    "            base_path,\n",
    "            f\"{all_layers}_layers_generated_delta={delta_attention}.pkl\"\n",
    "        )\n",
    "        try:\n",
    "            results_df = pd.read_pickle(path).T\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        parsed_results_dict = dict()\n",
    "\n",
    "        for epoch in range(len(results_df.columns)-1):\n",
    "            for (idx, result_epoch) in results_df.loc[:,f\"epoch {epoch}\"].items():\n",
    "                s = pd.Series(result_epoch)\\\n",
    "                    .apply(get_generated_text)\\\n",
    "\n",
    "                data = pd.DataFrame(s).T\n",
    "                data.index = [idx]\n",
    "\n",
    "                if not epoch in parsed_results_dict:\n",
    "                    parsed_results_dict[epoch] = []\n",
    "\n",
    "                parsed_results_dict[epoch].append(data)\n",
    "\n",
    "            parsed_results_dict[epoch] = pd.concat(parsed_results_dict[epoch])\n",
    "\n",
    "        all_dfs = []\n",
    "\n",
    "        for epoch in parsed_results_dict.keys():\n",
    "            temp_df = pd.melt(\n",
    "                parsed_results_dict[epoch].reset_index(),\n",
    "                var_name = \"instruction\",\n",
    "                value_name = \"generated_text\",\n",
    "                id_vars = \"index\",\n",
    "            )\n",
    "\n",
    "            temp_df[\"is_french\"] = temp_df[\"generated_text\"].apply(is_text_in_language)\n",
    "\n",
    "            temp_df[\"generation_epoch\"] = epoch\n",
    "\n",
    "            all_dfs.append(temp_df)\n",
    "\n",
    "        melted_df = pd.concat(all_dfs)\n",
    "\n",
    "        melted_df = pd.merge(\n",
    "            melted_df,\n",
    "            df[[\"context_length\", \"text\"]],\n",
    "            left_on=\"index\",\n",
    "            right_index=True\n",
    "        )\n",
    "\n",
    "        melted_df[\"context_length_bins\"] = pd.cut(\n",
    "            melted_df[\"context_length\"], \n",
    "            np.arange(0,6_500,500)\n",
    "        )\n",
    "\n",
    "        melted_df.dropna(inplace=True)\n",
    "\n",
    "        study_name = f\"$\\Delta$={delta_attention}\"\n",
    "        \n",
    "        if all_layers == 'first':\n",
    "            study_name= f\"$\\Delta$={delta_attention}, first layer only\"\n",
    "\n",
    "        elif  all_layers == 'all':\n",
    "\n",
    "            study_name = f\"$\\Delta$={delta_attention}\"\n",
    "            \n",
    "        melted_df[\"study\"] = study_name\n",
    "        \n",
    "        if delta_attention ==0:\n",
    "            melted_df[\"study\"] = f\"Raw model\"\n",
    "\n",
    "        all_results.append(melted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Raw model', '$\\\\Delta$=0.5', '$\\\\Delta$=1.0', '$\\\\Delta$=2.0',\n",
       "       '$\\\\Delta$=5.0'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(all_results).study.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_summaries_df = pd.read_csv(\"data/summarization_train.csv\", index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>text_idx</th>\n",
       "      <th>instruction</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Voici un r√©sum√© en fran√ßais du texte sur la pa...</td>\n",
       "      <td>The partition of Quebec refers to the secessio...</td>\n",
       "      <td>134</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Summarize in french: \\nThe partition of Quebec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voici un r√©sum√© en fran√ßais du texte :\\n\\n¬´ To...</td>\n",
       "      <td>Everything you know about ARGs is WRONG 22 Dec...</td>\n",
       "      <td>9341</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Summarize in french: \\nEverything you know abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voici un r√©sum√© en fran√ßais du texte original ...</td>\n",
       "      <td>Cyrstal Meth Addiction\\n\\nCrystal meth addicti...</td>\n",
       "      <td>2973</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Summarize in french: \\nCyrstal Meth Addiction\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voici un r√©sum√© en fran√ßais du texte :\\n\\nLe m...</td>\n",
       "      <td>Qu·∫£ng ƒê·ª©c is descriptive of meritorious attrib...</td>\n",
       "      <td>8280</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Summarize in french: \\nQu·∫£ng ƒê·ª©c is descriptiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Voici un r√©sum√© de l'article en fran√ßais :\\n\\n...</td>\n",
       "      <td>World Electioneering Entertainment 2016: 1,000...</td>\n",
       "      <td>3921</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Summarize in french: \\nWorld Electioneering En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Voici un r√©sum√© du texte en fran√ßais :\\n\\nUne ...</td>\n",
       "      <td>A New Zealand firm says it successfully triall...</td>\n",
       "      <td>7394</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Summarize in french: \\nA New Zealand firm says...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Voici un r√©sum√© du texte en fran√ßais :\\n\\nFaiz...</td>\n",
       "      <td>Originally Posted by Faizan Lakhani Originally...</td>\n",
       "      <td>6932</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Summarize in french: \\nOriginally Posted by Fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Voici un r√©sum√© du texte en fran√ßais :\\n\\n√Ä Da...</td>\n",
       "      <td>DAVAO CITY, Philippines ‚Äî Residents who are 18...</td>\n",
       "      <td>3943</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Summarize in french: \\nDAVAO CITY, Philippines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>LORSQUE LA RH√âTORIQUE DE LA DROITE TOURNE √Ä LA...</td>\n",
       "      <td>WHEN THE RIGHT‚ÄôS RHETORIC TURNS VIOLENT‚Ä¶. In t...</td>\n",
       "      <td>4922</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Summarize in french: \\nWHEN THE RIGHT‚ÄôS RHETOR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Voici un r√©sum√© du texte en fran√ßais :\\n\\nLe s...</td>\n",
       "      <td>The red Ford Expedition mounted the sidewalk a...</td>\n",
       "      <td>7645</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Summarize in french: \\nThe red Ford Expedition...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                target  \\\n",
       "0    Voici un r√©sum√© en fran√ßais du texte sur la pa...   \n",
       "1    Voici un r√©sum√© en fran√ßais du texte :\\n\\n¬´ To...   \n",
       "2    Voici un r√©sum√© en fran√ßais du texte original ...   \n",
       "3    Voici un r√©sum√© en fran√ßais du texte :\\n\\nLe m...   \n",
       "4    Voici un r√©sum√© de l'article en fran√ßais :\\n\\n...   \n",
       "..                                                 ...   \n",
       "235  Voici un r√©sum√© du texte en fran√ßais :\\n\\nUne ...   \n",
       "236  Voici un r√©sum√© du texte en fran√ßais :\\n\\nFaiz...   \n",
       "237  Voici un r√©sum√© du texte en fran√ßais :\\n\\n√Ä Da...   \n",
       "238  LORSQUE LA RH√âTORIQUE DE LA DROITE TOURNE √Ä LA...   \n",
       "239  Voici un r√©sum√© du texte en fran√ßais :\\n\\nLe s...   \n",
       "\n",
       "                                                  text  text_idx  \\\n",
       "0    The partition of Quebec refers to the secessio...       134   \n",
       "1    Everything you know about ARGs is WRONG 22 Dec...      9341   \n",
       "2    Cyrstal Meth Addiction\\n\\nCrystal meth addicti...      2973   \n",
       "3    Qu·∫£ng ƒê·ª©c is descriptive of meritorious attrib...      8280   \n",
       "4    World Electioneering Entertainment 2016: 1,000...      3921   \n",
       "..                                                 ...       ...   \n",
       "235  A New Zealand firm says it successfully triall...      7394   \n",
       "236  Originally Posted by Faizan Lakhani Originally...      6932   \n",
       "237  DAVAO CITY, Philippines ‚Äî Residents who are 18...      3943   \n",
       "238  WHEN THE RIGHT‚ÄôS RHETORIC TURNS VIOLENT‚Ä¶. In t...      4922   \n",
       "239  The red Ford Expedition mounted the sidewalk a...      7645   \n",
       "\n",
       "               instruction                                             prompt  \n",
       "0    Summarize in french:   Summarize in french: \\nThe partition of Quebec...  \n",
       "1    Summarize in french:   Summarize in french: \\nEverything you know abo...  \n",
       "2    Summarize in french:   Summarize in french: \\nCyrstal Meth Addiction\\...  \n",
       "3    Summarize in french:   Summarize in french: \\nQu·∫£ng ƒê·ª©c is descriptiv...  \n",
       "4    Summarize in french:   Summarize in french: \\nWorld Electioneering En...  \n",
       "..                     ...                                                ...  \n",
       "235  Summarize in french:   Summarize in french: \\nA New Zealand firm says...  \n",
       "236  Summarize in french:   Summarize in french: \\nOriginally Posted by Fa...  \n",
       "237  Summarize in french:   Summarize in french: \\nDAVAO CITY, Philippines...  \n",
       "238  Summarize in french:   Summarize in french: \\nWHEN THE RIGHT‚ÄôS RHETOR...  \n",
       "239  Summarize in french:   Summarize in french: \\nThe red Ford Expedition...  \n",
       "\n",
       "[240 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_summaries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['text'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>instruction</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>is_french</th>\n",
       "      <th>generation_epoch</th>\n",
       "      <th>context_length</th>\n",
       "      <th>text</th>\n",
       "      <th>context_length_bins</th>\n",
       "      <th>study</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>2015: 2eme referendum\\n\\nLe 26 novembre 2015,...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5995</td>\n",
       "      <td>The partition of Quebec refers to the secessio...</td>\n",
       "      <td>(5500, 6000]</td>\n",
       "      <td>$\\Delta$=0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7890</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>\"Les fous√©es de la vie\" en fran√ßais signifie ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5598</td>\n",
       "      <td>Hailed as the undisputed queens of ‚Äô60s-inspir...</td>\n",
       "      <td>(5500, 6000]</td>\n",
       "      <td>$\\Delta$=0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6952</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Venezuela est une r√©publique situ√©e √† l'ouest...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5446</td>\n",
       "      <td>Americans might be fooled by mass media misinf...</td>\n",
       "      <td>(5000, 5500]</td>\n",
       "      <td>$\\Delta$=0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2719</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Je suis pr√™t √† faire tout son mieux pour vous...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5428</td>\n",
       "      <td>Jahlil Okafor Is On His Way Up High-school bas...</td>\n",
       "      <td>(5000, 5500]</td>\n",
       "      <td>$\\Delta$=0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>760</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>En tant que fran√ßais, je pense que la langue ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5301</td>\n",
       "      <td>It is easily the most depraved little episode ...</td>\n",
       "      <td>(5000, 5500]</td>\n",
       "      <td>$\\Delta$=0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>3023</td>\n",
       "      <td>You must summarize the following text in french:</td>\n",
       "      <td>Summarize this text into French:\\nLes trois c...</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>302</td>\n",
       "      <td>statigr.am/kimbo_ks13 A study by three scienti...</td>\n",
       "      <td>(0, 500]</td>\n",
       "      <td>$\\Delta$=5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>7394</td>\n",
       "      <td>You must summarize the following text in french:</td>\n",
       "      <td>Bonner de broy et de la cellulose dans les ch...</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>256</td>\n",
       "      <td>A New Zealand firm says it successfully triall...</td>\n",
       "      <td>(0, 500]</td>\n",
       "      <td>$\\Delta$=5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>3943</td>\n",
       "      <td>You must summarize the following text in french:</td>\n",
       "      <td>You must summarize the text in French: Les r√©...</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>235</td>\n",
       "      <td>DAVAO CITY, Philippines ‚Äî Residents who are 18...</td>\n",
       "      <td>(0, 500]</td>\n",
       "      <td>$\\Delta$=5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>4922</td>\n",
       "      <td>You must summarize the following text in french:</td>\n",
       "      <td>Voilently.... \\n\\nDans le sillage des fusilla...</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>224</td>\n",
       "      <td>WHEN THE RIGHT‚ÄôS RHETORIC TURNS VIOLENT‚Ä¶. In t...</td>\n",
       "      <td>(0, 500]</td>\n",
       "      <td>$\\Delta$=5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>7645</td>\n",
       "      <td>You must summarize the following text in french:</td>\n",
       "      <td>\"L'exposition de Kalb avait malgr√© la bonne c...</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>220</td>\n",
       "      <td>The red Ford Expedition mounted the sidewalk a...</td>\n",
       "      <td>(0, 500]</td>\n",
       "      <td>$\\Delta$=5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12665 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                        instruction  \\\n",
       "0      134                              Summarize in french:    \n",
       "18    7890                              Summarize in french:    \n",
       "22    6952                              Summarize in french:    \n",
       "23    2719                              Summarize in french:    \n",
       "28     760                              Summarize in french:    \n",
       "..     ...                                                ...   \n",
       "714   3023  You must summarize the following text in french:    \n",
       "715   7394  You must summarize the following text in french:    \n",
       "717   3943  You must summarize the following text in french:    \n",
       "718   4922  You must summarize the following text in french:    \n",
       "719   7645  You must summarize the following text in french:    \n",
       "\n",
       "                                        generated_text is_french  \\\n",
       "0     2015: 2eme referendum\\n\\nLe 26 novembre 2015,...      True   \n",
       "18    \"Les fous√©es de la vie\" en fran√ßais signifie ...      True   \n",
       "22    Venezuela est une r√©publique situ√©e √† l'ouest...      True   \n",
       "23    Je suis pr√™t √† faire tout son mieux pour vous...      True   \n",
       "28    En tant que fran√ßais, je pense que la langue ...      True   \n",
       "..                                                 ...       ...   \n",
       "714   Summarize this text into French:\\nLes trois c...      True   \n",
       "715   Bonner de broy et de la cellulose dans les ch...      True   \n",
       "717   You must summarize the text in French: Les r√©...      True   \n",
       "718   Voilently.... \\n\\nDans le sillage des fusilla...      True   \n",
       "719   \"L'exposition de Kalb avait malgr√© la bonne c...      True   \n",
       "\n",
       "     generation_epoch  context_length  \\\n",
       "0                   0            5995   \n",
       "18                  0            5598   \n",
       "22                  0            5446   \n",
       "23                  0            5428   \n",
       "28                  0            5301   \n",
       "..                ...             ...   \n",
       "714                 9             302   \n",
       "715                 9             256   \n",
       "717                 9             235   \n",
       "718                 9             224   \n",
       "719                 9             220   \n",
       "\n",
       "                                                  text context_length_bins  \\\n",
       "0    The partition of Quebec refers to the secessio...        (5500, 6000]   \n",
       "18   Hailed as the undisputed queens of ‚Äô60s-inspir...        (5500, 6000]   \n",
       "22   Americans might be fooled by mass media misinf...        (5000, 5500]   \n",
       "23   Jahlil Okafor Is On His Way Up High-school bas...        (5000, 5500]   \n",
       "28   It is easily the most depraved little episode ...        (5000, 5500]   \n",
       "..                                                 ...                 ...   \n",
       "714  statigr.am/kimbo_ks13 A study by three scienti...            (0, 500]   \n",
       "715  A New Zealand firm says it successfully triall...            (0, 500]   \n",
       "717  DAVAO CITY, Philippines ‚Äî Residents who are 18...            (0, 500]   \n",
       "718  WHEN THE RIGHT‚ÄôS RHETORIC TURNS VIOLENT‚Ä¶. In t...            (0, 500]   \n",
       "719  The red Ford Expedition mounted the sidewalk a...            (0, 500]   \n",
       "\n",
       "            study  \n",
       "0    $\\Delta$=0.5  \n",
       "18   $\\Delta$=0.5  \n",
       "22   $\\Delta$=0.5  \n",
       "23   $\\Delta$=0.5  \n",
       "28   $\\Delta$=0.5  \n",
       "..            ...  \n",
       "714  $\\Delta$=5.0  \n",
       "715  $\\Delta$=5.0  \n",
       "717  $\\Delta$=5.0  \n",
       "718  $\\Delta$=5.0  \n",
       "719  $\\Delta$=5.0  \n",
       "\n",
       "[12665 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.query(\"is_french == 1 & study != 'Raw model'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.merge(\n",
    "    results_df,\n",
    "    llm_summaries_df[['text_idx', 'target']],\n",
    "    left_on='index',\n",
    "    right_on='text_idx'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instruction            8.314286\n",
       "generated_text         8.314286\n",
       "is_french              8.314286\n",
       "generation_epoch       8.314286\n",
       "context_length         8.314286\n",
       "text                   8.314286\n",
       "context_length_bins    8.314286\n",
       "study                  8.314286\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.query(\"is_french == 1 & study == 'Raw model'\").groupby(\"index\")\\\n",
    "    .count()\\\n",
    "    .mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2995.8806444143042"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['context_length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "    You are a helpful assistant that ranks summaries. \n",
    "    I will provide you a target summary and two summaries (0 and 1) of this text in French .\n",
    "\n",
    "    You must output which one is a better summary, based on both the quality of the summary and the quality of the French text.\n",
    "\n",
    "    Here is the target summary: \n",
    "    <text>\n",
    "    {target_summary}\n",
    "    </text>\n",
    "\n",
    "    Here is summary 0:\n",
    "    <0>\n",
    "    {summary_0}\n",
    "    </0>\n",
    "\n",
    "    Here is summary 1:\n",
    "    <1>\n",
    "    {summary_1}\n",
    "    </1>\n",
    "\n",
    "    Answer in the following format (JSON):\n",
    "    {{\n",
    "        \"best_summary\" : (0 or 1)\n",
    "        \"explaination\" : a short explaination why.\n",
    "    }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openai = OpenAI(\n",
    "    api_key=os.environ[\"DEEP_INFRA_API_KEY\"],\n",
    "    base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    ")\n",
    "model_name = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "\n",
    "def winning_rate_llm(\n",
    "    target_summary : str,\n",
    "    text_delta : str,\n",
    "    text_raw : str\n",
    "):\n",
    "    \n",
    "    index_of_delta = int(np.random.random() > 1.2)\n",
    "    \n",
    "    shuffling_dict = {\n",
    "        index_of_delta : text_delta,\n",
    "        1-index_of_delta: text_raw\n",
    "    }\n",
    "\n",
    "    inverse_shuffling_map = {\n",
    "        index_of_delta : \"modified\",\n",
    "        1 - index_of_delta: \"raw\"\n",
    "    }\n",
    "\n",
    "    prompt = TEMPLATE.format(\n",
    "        target_summary = target_summary,\n",
    "        summary_0 = shuffling_dict[0],\n",
    "        summary_1 = shuffling_dict[1]\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    chat_completion = openai.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        stream=False,\n",
    "    )\n",
    "    \n",
    "    generated_text = chat_completion\\\n",
    "        .choices[0]\\\n",
    "        .message\\\n",
    "        .content\n",
    "    prompt_tokens = chat_completion\\\n",
    "        .usage\\\n",
    "        .prompt_tokens\n",
    "    output_tokens = chat_completion\\\n",
    "        .usage\\\n",
    "        .completion_tokens\n",
    "    \n",
    "    try:\n",
    "        generated_json = json.loads(generated_text)\n",
    "        generated_json['best_summary'] = inverse_shuffling_map[generated_json['best_summary']]\n",
    "\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "\n",
    "    return generated_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "texts = np.random.choice(eval_df.text_idx.unique(), 30)\n",
    "\n",
    "mask = eval_df.text_idx.isin(texts)\n",
    "experiment_df = eval_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_model_performance = experiment_df.query(f\"study == 'Raw model' & is_french == 1 & instruction == 'Summarize in french: '\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparing french text generated by $\\Delta$=0.5 to raw model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "study_winning_rates = dict()\n",
    "\n",
    "for i, study_name in enumerate(experiment_df.study.unique()):\n",
    "    if study_name == 'Raw model':\n",
    "        continue\n",
    "\n",
    "    \n",
    "    clear_output()\n",
    "    print(f\"comparing french text generated by {study_name} to raw model\")\n",
    "    winning_dict = dict()\n",
    "    \n",
    "    augmented_model_performance = experiment_df.query(f\"study == '{study_name}' & is_french == 1 & instruction == 'Summarize in french: '\")\n",
    "\n",
    "    for idx, row in tqdm(augmented_model_performance.iterrows(), total = len(augmented_model_performance)):\n",
    "        text_idx = row['index']\n",
    "        base_text = row['text']\n",
    "        target_summary = row['target']\n",
    "        generated_text_delta = row['generated_text']\n",
    "        \n",
    "        raw_model_text_df = raw_model_performance.query(f\"index == {text_idx}\")\n",
    "\n",
    "        records = []\n",
    "        for _, raw_model_row in raw_model_text_df.iterrows():\n",
    "            generated_text_raw_model = raw_model_row['generated_text']\n",
    "\n",
    "            generated_json = winning_rate_llm(target_summary, generated_text_delta, generated_text_raw_model)\n",
    "            records.append(generated_json)\n",
    "\n",
    "        winning_dict[text_idx] = records\n",
    "    \n",
    "    winning_rate_df = pd.DataFrame(pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in winning_dict.items() ])))\n",
    "\n",
    "    study_winning_rates[study_name] = winning_rate_df\n",
    "\n",
    "#     j = (i-1) // 2\n",
    "#     k = (i-1) % 2\n",
    "#     sns.heatmap(winning_rate_df, cmap='viridis' ,ax= axs[j][k])\n",
    "#     axs[j][k].set_title(f\"Winning matrix of sutdy : {study_name} - winning_rate = {round(winning_rate_df.mean().mean(),2)}\")\n",
    "\n",
    "\n",
    "# fig.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"best_summary\" : 0,\n",
      "\"explaination\" : \"Summary 0 is totally unrelated to the target summary, but at least it's a coherent text in French. Summary 1 is also unrelated and lacks coherence, with sentences that don't form a logical narrative. Neither summary is a good representation of the target text, but Summary 0 is a better written French text.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_summary': 'modified',\n",
       " 'explaination': \"Summary 0 is totally unrelated to the target summary, but at least it's a coherent text in French. Summary 1 is also unrelated and lacks coherence, with sentences that don't form a logical narrative. Neither summary is a good representation of the target text, but Summary 0 is a better written French text.\"}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winning_rate_llm(target_summary, generated_text_delta, generated_text_raw_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>instruction</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>is_french</th>\n",
       "      <th>generation_epoch</th>\n",
       "      <th>context_length</th>\n",
       "      <th>text</th>\n",
       "      <th>context_length_bins</th>\n",
       "      <th>study</th>\n",
       "      <th>text_idx</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>7686</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Le commentaire original √©tait :\\n\\n\"Ce dernie...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4138</td>\n",
       "      <td>Hardware\\n\\nI've had the Moto X for five days ...</td>\n",
       "      <td>(4000, 4500]</td>\n",
       "      <td>$\\Delta$=0.5</td>\n",
       "      <td>7686</td>\n",
       "      <td>Voici un r√©sum√© du texte en fran√ßais :\\n\\nJ'ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5138</th>\n",
       "      <td>4762</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Quality of life (QOL) est un concept g√©n√©ral ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3527</td>\n",
       "      <td>Quality of life (QOL) is an overarching term f...</td>\n",
       "      <td>(3500, 4000]</td>\n",
       "      <td>$\\Delta$=0.5</td>\n",
       "      <td>4762</td>\n",
       "      <td>La qualit√© de vie (QOL) est un terme englobant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>1294</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Summarized French:\\n\\nNous sommes en m√™me pos...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3355</td>\n",
       "      <td>With tonight's win, Florida is now 44-3 and st...</td>\n",
       "      <td>(3000, 3500]</td>\n",
       "      <td>$\\Delta$=0.5</td>\n",
       "      <td>1294</td>\n",
       "      <td>Voici un r√©sum√© du texte en fran√ßais :\\n\\nAvec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>247</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Le lac Grand Slave (en fran√ßais : Grand lac d...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2654</td>\n",
       "      <td>Large lake in the Northwest Territories of Can...</td>\n",
       "      <td>(2500, 3000]</td>\n",
       "      <td>$\\Delta$=0.5</td>\n",
       "      <td>247</td>\n",
       "      <td>Voici un r√©sum√© du texte en fran√ßais :\\n\\nLe g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>8927</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Sibyl Moon est un artiste ind√©pendant qui est...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2067</td>\n",
       "      <td>NetHack\\n\\nThe first roguelike I played was Ne...</td>\n",
       "      <td>(2000, 2500]</td>\n",
       "      <td>$\\Delta$=0.5</td>\n",
       "      <td>8927</td>\n",
       "      <td>Voici un r√©sum√© du texte en fran√ßais :\\n\\nNetH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12183</th>\n",
       "      <td>4487</td>\n",
       "      <td>You must summarize the following text in french:</td>\n",
       "      <td>Here's a possible translation of the text int...</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>1319</td>\n",
       "      <td>Artist's illustration of an asteroid that has ...</td>\n",
       "      <td>(1000, 1500]</td>\n",
       "      <td>$\\Delta$=0.5</td>\n",
       "      <td>4487</td>\n",
       "      <td>Voici un r√©sum√© du texte en fran√ßais :\\n\\n Dan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12186</th>\n",
       "      <td>6112</td>\n",
       "      <td>You must summarize the following text in french:</td>\n",
       "      <td>L'Occupy Wall Street a besoin d'artistes !\\n\\...</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>1254</td>\n",
       "      <td>Call for Artists: Wall Street Occupennial!\\n\\n...</td>\n",
       "      <td>(1000, 1500]</td>\n",
       "      <td>$\\Delta$=0.5</td>\n",
       "      <td>6112</td>\n",
       "      <td>Voici un r√©sum√© du texte en fran√ßais :\\n\\nAppe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12197</th>\n",
       "      <td>3130</td>\n",
       "      <td>You must summarize the following text in french:</td>\n",
       "      <td>Le ancien agent de renseignement central (CIA...</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>859</td>\n",
       "      <td>A former Central Intelligence Agency (CIA) ope...</td>\n",
       "      <td>(500, 1000]</td>\n",
       "      <td>$\\Delta$=0.5</td>\n",
       "      <td>3130</td>\n",
       "      <td>Un ancien op√©rateur de la Central Intelligence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12205</th>\n",
       "      <td>8285</td>\n",
       "      <td>You must summarize the following text in french:</td>\n",
       "      <td>Les Browns commencent leur premi√®re partie de...</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>731</td>\n",
       "      <td>Tom Dahlin/Getty Images\\n\\nThe Cleveland Brown...</td>\n",
       "      <td>(500, 1000]</td>\n",
       "      <td>$\\Delta$=0.5</td>\n",
       "      <td>8285</td>\n",
       "      <td>Voici un r√©sum√© du texte en fran√ßais :\\n\\nLes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12230</th>\n",
       "      <td>7394</td>\n",
       "      <td>You must summarize the following text in french:</td>\n",
       "      <td>Une entreprise n√©o-z√©landaise a √©t√© r√©ussite ...</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>256</td>\n",
       "      <td>A New Zealand firm says it successfully triall...</td>\n",
       "      <td>(0, 500]</td>\n",
       "      <td>$\\Delta$=0.5</td>\n",
       "      <td>7394</td>\n",
       "      <td>Voici un r√©sum√© du texte en fran√ßais :\\n\\nUne ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                        instruction  \\\n",
       "5110    7686                              Summarize in french:    \n",
       "5138    4762                              Summarize in french:    \n",
       "5145    1294                              Summarize in french:    \n",
       "5169     247                              Summarize in french:    \n",
       "5196    8927                              Summarize in french:    \n",
       "...      ...                                                ...   \n",
       "12183   4487  You must summarize the following text in french:    \n",
       "12186   6112  You must summarize the following text in french:    \n",
       "12197   3130  You must summarize the following text in french:    \n",
       "12205   8285  You must summarize the following text in french:    \n",
       "12230   7394  You must summarize the following text in french:    \n",
       "\n",
       "                                          generated_text is_french  \\\n",
       "5110    Le commentaire original √©tait :\\n\\n\"Ce dernie...      True   \n",
       "5138    Quality of life (QOL) est un concept g√©n√©ral ...      True   \n",
       "5145    Summarized French:\\n\\nNous sommes en m√™me pos...      True   \n",
       "5169    Le lac Grand Slave (en fran√ßais : Grand lac d...      True   \n",
       "5196    Sibyl Moon est un artiste ind√©pendant qui est...      True   \n",
       "...                                                  ...       ...   \n",
       "12183   Here's a possible translation of the text int...      True   \n",
       "12186   L'Occupy Wall Street a besoin d'artistes !\\n\\...      True   \n",
       "12197   Le ancien agent de renseignement central (CIA...      True   \n",
       "12205   Les Browns commencent leur premi√®re partie de...      True   \n",
       "12230   Une entreprise n√©o-z√©landaise a √©t√© r√©ussite ...      True   \n",
       "\n",
       "       generation_epoch  context_length  \\\n",
       "5110                  0            4138   \n",
       "5138                  0            3527   \n",
       "5145                  0            3355   \n",
       "5169                  0            2654   \n",
       "5196                  0            2067   \n",
       "...                 ...             ...   \n",
       "12183                 9            1319   \n",
       "12186                 9            1254   \n",
       "12197                 9             859   \n",
       "12205                 9             731   \n",
       "12230                 9             256   \n",
       "\n",
       "                                                    text context_length_bins  \\\n",
       "5110   Hardware\\n\\nI've had the Moto X for five days ...        (4000, 4500]   \n",
       "5138   Quality of life (QOL) is an overarching term f...        (3500, 4000]   \n",
       "5145   With tonight's win, Florida is now 44-3 and st...        (3000, 3500]   \n",
       "5169   Large lake in the Northwest Territories of Can...        (2500, 3000]   \n",
       "5196   NetHack\\n\\nThe first roguelike I played was Ne...        (2000, 2500]   \n",
       "...                                                  ...                 ...   \n",
       "12183  Artist's illustration of an asteroid that has ...        (1000, 1500]   \n",
       "12186  Call for Artists: Wall Street Occupennial!\\n\\n...        (1000, 1500]   \n",
       "12197  A former Central Intelligence Agency (CIA) ope...         (500, 1000]   \n",
       "12205  Tom Dahlin/Getty Images\\n\\nThe Cleveland Brown...         (500, 1000]   \n",
       "12230  A New Zealand firm says it successfully triall...            (0, 500]   \n",
       "\n",
       "              study  text_idx  \\\n",
       "5110   $\\Delta$=0.5      7686   \n",
       "5138   $\\Delta$=0.5      4762   \n",
       "5145   $\\Delta$=0.5      1294   \n",
       "5169   $\\Delta$=0.5       247   \n",
       "5196   $\\Delta$=0.5      8927   \n",
       "...             ...       ...   \n",
       "12183  $\\Delta$=0.5      4487   \n",
       "12186  $\\Delta$=0.5      6112   \n",
       "12197  $\\Delta$=0.5      3130   \n",
       "12205  $\\Delta$=0.5      8285   \n",
       "12230  $\\Delta$=0.5      7394   \n",
       "\n",
       "                                                  target  \n",
       "5110   Voici un r√©sum√© du texte en fran√ßais :\\n\\nJ'ai...  \n",
       "5138   La qualit√© de vie (QOL) est un terme englobant...  \n",
       "5145   Voici un r√©sum√© du texte en fran√ßais :\\n\\nAvec...  \n",
       "5169   Voici un r√©sum√© du texte en fran√ßais :\\n\\nLe g...  \n",
       "5196   Voici un r√©sum√© du texte en fran√ßais :\\n\\nNetH...  \n",
       "...                                                  ...  \n",
       "12183  Voici un r√©sum√© du texte en fran√ßais :\\n\\n Dan...  \n",
       "12186  Voici un r√©sum√© du texte en fran√ßais :\\n\\nAppe...  \n",
       "12197  Un ancien op√©rateur de la Central Intelligence...  \n",
       "12205  Voici un r√©sum√© du texte en fran√ßais :\\n\\nLes ...  \n",
       "12230  Voici un r√©sum√© du texte en fran√ßais :\\n\\nUne ...  \n",
       "\n",
       "[358 rows x 11 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5110    [{'best_summary': 'raw', 'explaination': 'Summ...\n",
       "5138    [{'best_summary': 'raw', 'explaination': 'Summ...\n",
       "5145    [{'best_summary': 'modified', 'explaination': ...\n",
       "5169    [{'best_summary': 'modified', 'explaination': ...\n",
       "5196    [{'best_summary': 'raw', 'explaination': 'Summ...\n",
       "5226    [{'best_summary': 'raw', 'explaination': 'Summ...\n",
       "5230    [{'best_summary': 'modified', 'explaination': ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(winning_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5138</th>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>{'best_summary': 'raw', 'explanation': 'Summar...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>{'best_summary': 'raw', 'explanation': 'Summar...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explanation': 'Summar...</td>\n",
       "      <td>{'best_summary': 'raw', 'explanation': 'Summar...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'best_summary': 'raw', 'explanation': 'Summar...</td>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>{'best_summary': 'raw', 'explanation': 'Summar...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5230</th>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>{'best_summary': 'modified', 'explanation': 'S...</td>\n",
       "      <td>{'best_summary': 'raw', 'explaination': 'Summa...</td>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>{'best_summary': 'modified', 'explaination': '...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0   \\\n",
       "5110  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5138  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5145  {'best_summary': 'modified', 'explaination': '...   \n",
       "5169  {'best_summary': 'modified', 'explaination': '...   \n",
       "5196  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5226  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5230  {'best_summary': 'modified', 'explaination': '...   \n",
       "\n",
       "                                                     1   \\\n",
       "5110  {'best_summary': 'modified', 'explaination': '...   \n",
       "5138  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5145  {'best_summary': 'raw', 'explanation': 'Summar...   \n",
       "5169  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5196  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5226  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5230  {'best_summary': 'modified', 'explaination': '...   \n",
       "\n",
       "                                                     2   \\\n",
       "5110  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5138  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5145  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5169  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5196  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5226  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5230  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "\n",
       "                                                     3   \\\n",
       "5110  {'best_summary': 'modified', 'explaination': '...   \n",
       "5138  {'best_summary': 'modified', 'explaination': '...   \n",
       "5145  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5169  {'best_summary': 'modified', 'explaination': '...   \n",
       "5196  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5226  {'best_summary': 'raw', 'explanation': 'Summar...   \n",
       "5230  {'best_summary': 'modified', 'explaination': '...   \n",
       "\n",
       "                                                     4   \\\n",
       "5110  {'best_summary': 'modified', 'explaination': '...   \n",
       "5138  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5145  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5169  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5196                                               None   \n",
       "5226  {'best_summary': 'raw', 'explanation': 'Summar...   \n",
       "5230  {'best_summary': 'modified', 'explaination': '...   \n",
       "\n",
       "                                                     5   \\\n",
       "5110  {'best_summary': 'modified', 'explaination': '...   \n",
       "5138  {'best_summary': 'modified', 'explaination': '...   \n",
       "5145  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5169  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5196  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5226                                               None   \n",
       "5230                                               None   \n",
       "\n",
       "                                                     6   \\\n",
       "5110  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5138  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5145  {'best_summary': 'modified', 'explaination': '...   \n",
       "5169  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5196  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5226  {'best_summary': 'raw', 'explanation': 'Summar...   \n",
       "5230  {'best_summary': 'modified', 'explaination': '...   \n",
       "\n",
       "                                                     7   \\\n",
       "5110  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5138                                                NaN   \n",
       "5145  {'best_summary': 'raw', 'explanation': 'Summar...   \n",
       "5169  {'best_summary': 'modified', 'explaination': '...   \n",
       "5196  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5226  {'best_summary': 'modified', 'explaination': '...   \n",
       "5230  {'best_summary': 'modified', 'explanation': 'S...   \n",
       "\n",
       "                                                     8   \\\n",
       "5110                                                NaN   \n",
       "5138                                                NaN   \n",
       "5145                                               None   \n",
       "5169                                                NaN   \n",
       "5196  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5226  {'best_summary': 'raw', 'explanation': 'Summar...   \n",
       "5230  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "\n",
       "                                                     9   \\\n",
       "5110                                                NaN   \n",
       "5138                                                NaN   \n",
       "5145                                                NaN   \n",
       "5169                                                NaN   \n",
       "5196  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5226  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5230  {'best_summary': 'modified', 'explaination': '...   \n",
       "\n",
       "                                                     10  \\\n",
       "5110                                                NaN   \n",
       "5138                                                NaN   \n",
       "5145                                                NaN   \n",
       "5169                                                NaN   \n",
       "5196                                                NaN   \n",
       "5226  {'best_summary': 'raw', 'explaination': 'Summa...   \n",
       "5230  {'best_summary': 'modified', 'explaination': '...   \n",
       "\n",
       "                                                     11  \n",
       "5110                                                NaN  \n",
       "5138                                                NaN  \n",
       "5145                                                NaN  \n",
       "5169                                                NaN  \n",
       "5196                                                NaN  \n",
       "5226  {'best_summary': 'raw', 'explaination': 'Summa...  \n",
       "5230                                                NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in winning_dict.items() ]))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>instruction</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>is_french</th>\n",
       "      <th>generation_epoch</th>\n",
       "      <th>context_length</th>\n",
       "      <th>text</th>\n",
       "      <th>context_length_bins</th>\n",
       "      <th>study</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>134</td>\n",
       "      <td>You must summarize the following text in french:</td>\n",
       "      <td>L'article partition:\\n\\nL'article Partition e...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>5995</td>\n",
       "      <td>The partition of Quebec refers to the secessio...</td>\n",
       "      <td>(5500, 6000]</td>\n",
       "      <td>Raw model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>134</td>\n",
       "      <td>Important: Summarize in french:</td>\n",
       "      <td>Fr√©d√©ric Passy. Le Partition. √âdition parisie...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>5995</td>\n",
       "      <td>The partition of Quebec refers to the secessio...</td>\n",
       "      <td>(5500, 6000]</td>\n",
       "      <td>Raw model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134</td>\n",
       "      <td>Summarize in french:</td>\n",
       "      <td>Notes:\\n[1] Jean-Louis Chartrand, \"L'influenc...</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>5995</td>\n",
       "      <td>The partition of Quebec refers to the secessio...</td>\n",
       "      <td>(5500, 6000]</td>\n",
       "      <td>Raw model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>134</td>\n",
       "      <td>You must summarize the following text in french:</td>\n",
       "      <td>Partition de la province de Qu√©bec √† l'√©tat d...</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>5995</td>\n",
       "      <td>The partition of Quebec refers to the secessio...</td>\n",
       "      <td>(5500, 6000]</td>\n",
       "      <td>Raw model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>134</td>\n",
       "      <td>Important: Summarize in french:</td>\n",
       "      <td>Here is an answer to your question in French:...</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>5995</td>\n",
       "      <td>The partition of Quebec refers to the secessio...</td>\n",
       "      <td>(5500, 6000]</td>\n",
       "      <td>Raw model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>134</td>\n",
       "      <td>You must summarize the following text in french:</td>\n",
       "      <td>Pour faire comprendre et traduire ce texte ca...</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>5995</td>\n",
       "      <td>The partition of Quebec refers to the secessio...</td>\n",
       "      <td>(5500, 6000]</td>\n",
       "      <td>Raw model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                        instruction  \\\n",
       "480    134  You must summarize the following text in french:    \n",
       "240    134                   Important: Summarize in french:    \n",
       "0      134                              Summarize in french:    \n",
       "480    134  You must summarize the following text in french:    \n",
       "240    134                   Important: Summarize in french:    \n",
       "480    134  You must summarize the following text in french:    \n",
       "\n",
       "                                        generated_text is_french  \\\n",
       "480   L'article partition:\\n\\nL'article Partition e...      True   \n",
       "240   Fr√©d√©ric Passy. Le Partition. √âdition parisie...      True   \n",
       "0     Notes:\\n[1] Jean-Louis Chartrand, \"L'influenc...      True   \n",
       "480   Partition de la province de Qu√©bec √† l'√©tat d...      True   \n",
       "240   Here is an answer to your question in French:...      True   \n",
       "480   Pour faire comprendre et traduire ce texte ca...      True   \n",
       "\n",
       "     generation_epoch  context_length  \\\n",
       "480                 1            5995   \n",
       "240                 2            5995   \n",
       "0                   4            5995   \n",
       "480                 4            5995   \n",
       "240                 6            5995   \n",
       "480                 6            5995   \n",
       "\n",
       "                                                  text context_length_bins  \\\n",
       "480  The partition of Quebec refers to the secessio...        (5500, 6000]   \n",
       "240  The partition of Quebec refers to the secessio...        (5500, 6000]   \n",
       "0    The partition of Quebec refers to the secessio...        (5500, 6000]   \n",
       "480  The partition of Quebec refers to the secessio...        (5500, 6000]   \n",
       "240  The partition of Quebec refers to the secessio...        (5500, 6000]   \n",
       "480  The partition of Quebec refers to the secessio...        (5500, 6000]   \n",
       "\n",
       "         study  \n",
       "480  Raw model  \n",
       "240  Raw model  \n",
       "0    Raw model  \n",
       "480  Raw model  \n",
       "240  Raw model  \n",
       "480  Raw model  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_model_performance.query(f\"index == {text_idx}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
