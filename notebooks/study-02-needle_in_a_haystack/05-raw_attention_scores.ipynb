{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel, \\\n",
    "  BitsAndBytesConfig, GPTQConfig\n",
    "import os\n",
    "\n",
    "while \"notebooks\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from langdetect import detect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset\n",
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from copy import deepcopy\n",
    "import gc\n",
    "from sklearn.metrics import  roc_auc_score, average_precision_score\n",
    "\n",
    "from src.utils import rotate_half, apply_rotary_pos_emb, repeat_kv, \\\n",
    "    get_context_length, get_generated_text, FileReader, is_text_in_language, rolling_mean, insert_needle\n",
    "\n",
    "from src.attention_saver import Mistral7BAttentionSaver\n",
    "from src.influence.influence import Influence, AttentionRollout\n",
    "\n",
    "import scienceplots\n",
    "plt.style.use(['science','no-latex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5df2ccbb89b4451a3c938dee36f7188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    cache_dir = \"/Data\"    \n",
    ")\n",
    "\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    quantization_config = quantization_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"eager\",\n",
    "    cache_dir = \"/Data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = Mistral7BAttentionSaver(\n",
    "    base_model,\n",
    "    tokenizer,\n",
    "    should_save_params=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:20<00:00, 477.29it/s]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df = load_dataset(\"stas/openwebtext-10k\", cache_dir=\"/Data\")['train'].to_pandas()\n",
    "df[\"text_len\"] = df[\"text\"].apply(lambda x: len(x.split(\" \")))\n",
    "df['context_length'] = df['text'].progress_apply(get_context_length, tokenizer = tokenizer)\n",
    "\n",
    "\n",
    "chunks = []\n",
    "for n in range (8):\n",
    "    samples = df.query(f\"context_length > {500*n} & context_length < {500*(n+1)}\")\\\n",
    "        .sample(15, random_state = 43)\n",
    "    \n",
    "    chunks.append(samples)\n",
    "\n",
    "# study_df = pd.concat(chunks)\\\n",
    "#     .sort_values(\"context_length\", ascending = False)\n",
    "\n",
    "indexes = [8263, 5418, 9572, 6251, 2927, 6800, 7716, 408, 4851, 8568, 6944,\n",
    "       3651, 247, 703, 1176, 9336, 6207, 9683, 8572, 2193, 6571, 5087,\n",
    "       4122, 4791, 8952, 1654, 3119, 9263, 6594, 9948, 3177, 1569, 1686,\n",
    "       1726, 6939, 7577, 1799, 8927, 6281, 9942, 5392, 7620, 9842, 3979,\n",
    "       6532, 5037, 8052, 2590, 8459, 1172, 6969, 2731, 5064, 3526, 6461,\n",
    "       6565, 2537, 9679, 695, 2235, 8894, 7514, 2454, 1656, 7796, 9852,\n",
    "       8200, 7016, 6692, 3507, 3001, 8227, 6280, 6537, 8620, 9484, 2028,\n",
    "       5560, 5645, 412, 6559, 1497, 928, 7862, 6798, 6874, 4734, 2956,\n",
    "       3601, 6201, 9017, 2673, 433, 4861, 5407, 9311, 6810, 9155, 2626,\n",
    "       6219, 9301, 3564, 1413, 7146, 7169, 3749, 9734, 5389, 8266, 3224,\n",
    "       1391, 9375, 697, 2319, 3099, 8065, 5834, 8867, 8841, 5378]\n",
    "\n",
    "study_df = df.iloc[indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the needle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "needle = \"\\nThe best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.\\n\"\n",
    "question = \"Your objective is to answer the following question based on the context: \\nWhat is the best thing to do in San Francisco? \\nDon't give information outside the document or repeat our findings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.85it/s]\n"
     ]
    }
   ],
   "source": [
    "all_df = []\n",
    "\n",
    "instructions = [needle]\n",
    "\n",
    "for instruction in instructions:\n",
    "    for depth_percent in tqdm(range(0, 125, 25)):\n",
    "\n",
    "        percent_df = study_df.apply(\n",
    "            insert_needle, \n",
    "            depth_percent = depth_percent, \n",
    "            question = question,\n",
    "            needle = instruction, \n",
    "            axis = 1\n",
    "        )\n",
    "\n",
    "        all_df.append(percent_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = pd.concat(all_df)\\\n",
    "    .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      8263\n",
       "1      5418\n",
       "2      9572\n",
       "3      6251\n",
       "4      2927\n",
       "       ... \n",
       "595    8065\n",
       "596    5834\n",
       "597    8867\n",
       "598    8841\n",
       "599    5378\n",
       "Name: index, Length: 600, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_df['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [10:33<00:00,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "saver.set_delta_attention(0)\n",
    "raw_attention_dict = dict()\n",
    "\n",
    "for idx, row in tqdm(samples_df.iterrows(), total= len(samples_df)):\n",
    "\n",
    "    saver.reset_internal_parameters()\n",
    "    instruction = row['needle']\n",
    "    text = row['new_text']\n",
    "    index = row['index']\n",
    "    depth = row['depth']\n",
    "    prompt = f\"{instruction}\\n{text}\"\n",
    "\n",
    "    message = [ {\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    template = tokenizer.apply_chat_template(\n",
    "        message,\n",
    "        tokenize= False\n",
    "    )\n",
    "\n",
    "    splits = template.split(instruction)\n",
    "    initial_prompt = splits[0]\n",
    "    context = instruction.join(splits[1:])\n",
    "\n",
    "    assert (hash(initial_prompt+instruction+context) == hash(template)), \"Error in spliting strings. Initial and final string does not match\"\n",
    "\n",
    "    initial_tokens = tokenizer.encode(initial_prompt, return_tensors='pt')\n",
    "    instruction_tokens = tokenizer.encode(\n",
    "        instruction, \n",
    "        return_tensors='pt', \n",
    "        add_special_tokens=False\n",
    "    )\n",
    "    context_tokens = tokenizer.encode(\n",
    "        context, \n",
    "        return_tensors='pt',\n",
    "        add_special_tokens=False\n",
    "    )\n",
    "\n",
    "    start_idx = initial_tokens.size(1)\n",
    "    end_idx = start_idx + instruction_tokens.size(1)\n",
    "\n",
    "    saver.set_reference_tokens(start_idx, end_idx)\n",
    "    \n",
    "    tokens = torch.concat([\n",
    "        initial_tokens.squeeze(), \n",
    "        instruction_tokens.squeeze(),\n",
    "        context_tokens.squeeze()\n",
    "    ]).unsqueeze(0)\n",
    "\n",
    "    q = tokenizer.decode(tokens.squeeze()[start_idx: end_idx])\n",
    "\n",
    "    assert instruction in q, \"Error in tokenization. Not giving attention to correct tokens\"\n",
    "\n",
    "    tokens2 = tokenizer(template, return_tensors='pt')\n",
    "\n",
    "    assert (abs(tokens.shape[1] - tokens2['input_ids'].shape[1]) <=5 ), \"Error in tokenization. Tokens do not match\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = base_model(tokens)\n",
    "\n",
    "    last_attn_matrix = saver.internal_parameters[-1]\\\n",
    "        ['avg_attention_heads']\\\n",
    "        .squeeze()\n",
    "    last_token_importances = last_attn_matrix\\\n",
    "        [-1, start_idx:end_idx]\\\n",
    "        .mean()\\\n",
    "        .item()\n",
    "\n",
    "    raw_attention_dict[(index, depth)] = last_token_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(raw_attention_dict).reset_index()\\\n",
    "    .rename(columns = {\n",
    "        \"level_0\": \"index\", \n",
    "        \"level_1\": \"depth\",\n",
    "        0 : \"attention_scores\"\n",
    "    })\\\n",
    "    .to_parquet(\"data/influences/needle/raw_attention_scores.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_scores_df = pd.read_parquet(\n",
    "    \"data/influences/needle/raw_attention_scores.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text_df = pd.read_parquet(\"data/influences/needle/generated_text4.parquet\")\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns = {\"level_0\": \"text_idx\", \"level_1\":\"depth\", 0: \"generated_text\"})\n",
    "\n",
    "\n",
    "generated_text_df['generated_text'] = generated_text_df['generated_text']\\\n",
    "    .apply(lambda x: x.split('[/INST]')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text_idx</th>\n",
       "      <th>depth</th>\n",
       "      <th>epoch</th>\n",
       "      <th>generated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>The best thing to do in San Francisco is eat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8263</td>\n",
       "      <td>49.181606</td>\n",
       "      <td>0</td>\n",
       "      <td>Based on the context, there is no direct answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8263</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Based on the provided context, the best thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8263</td>\n",
       "      <td>74.175110</td>\n",
       "      <td>0</td>\n",
       "      <td>The best thing to do in San Francisco, based ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8263</td>\n",
       "      <td>24.863601</td>\n",
       "      <td>0</td>\n",
       "      <td>Based on the input provided, the best thing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5975</th>\n",
       "      <td>5975</td>\n",
       "      <td>8841</td>\n",
       "      <td>55.088702</td>\n",
       "      <td>9</td>\n",
       "      <td>There is no evidence to suggest that anything...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>5976</td>\n",
       "      <td>5378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>The best thing to do in San Francisco is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>5977</td>\n",
       "      <td>5378</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>Based on the given context, the best thing to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>5978</td>\n",
       "      <td>5378</td>\n",
       "      <td>18.204804</td>\n",
       "      <td>9</td>\n",
       "      <td>Unfortunately, I cannot provide an answer to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>5979</td>\n",
       "      <td>5378</td>\n",
       "      <td>64.854614</td>\n",
       "      <td>9</td>\n",
       "      <td>The best thing to do in San Francisco, accord...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5980 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  text_idx       depth  epoch  \\\n",
       "0         0      8263    0.000000      0   \n",
       "1         1      8263   49.181606      0   \n",
       "2         2      8263  100.000000      0   \n",
       "3         3      8263   74.175110      0   \n",
       "4         4      8263   24.863601      0   \n",
       "...     ...       ...         ...    ...   \n",
       "5975   5975      8841   55.088702      9   \n",
       "5976   5976      5378    0.000000      9   \n",
       "5977   5977      5378  100.000000      9   \n",
       "5978   5978      5378   18.204804      9   \n",
       "5979   5979      5378   64.854614      9   \n",
       "\n",
       "                                         generated_text  \n",
       "0      The best thing to do in San Francisco is eat ...  \n",
       "1      Based on the context, there is no direct answ...  \n",
       "2      Based on the provided context, the best thing...  \n",
       "3      The best thing to do in San Francisco, based ...  \n",
       "4      Based on the input provided, the best thing t...  \n",
       "...                                                 ...  \n",
       "5975   There is no evidence to suggest that anything...  \n",
       "5976   The best thing to do in San Francisco is not ...  \n",
       "5977   Based on the given context, the best thing to...  \n",
       "5978   Unfortunately, I cannot provide an answer to ...  \n",
       "5979   The best thing to do in San Francisco, accord...  \n",
       "\n",
       "[5980 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_probabilities_df = pd.merge(\n",
    "    generated_text_df, \n",
    "    attention_scores_df,\n",
    "    left_on = [\"text_idx\",'depth'],\n",
    "    right_on= [\"index\",'depth']\n",
    ")\n",
    "\n",
    "attention_probabilities_df['score'] = attention_probabilities_df['generated_text'].apply(lambda x: 'dolores' in x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>attention_scores</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_idx</th>\n",
       "      <th>depth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">247</th>\n",
       "      <th>0.000000</th>\n",
       "      <td>0.002834</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.683399</th>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.746719</th>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74.441630</th>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.000000</th>\n",
       "      <td>0.002380</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">9948</th>\n",
       "      <th>0.000000</th>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.416404</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.526814</th>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74.458465</th>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.000000</th>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     attention_scores  score\n",
       "text_idx depth                              \n",
       "247      0.000000            0.002834    0.6\n",
       "         24.683399           0.002472    0.3\n",
       "         49.746719           0.002420    0.2\n",
       "         74.441630           0.002537    0.0\n",
       "         100.000000          0.002380    0.4\n",
       "...                               ...    ...\n",
       "9948     0.000000            0.003086    0.6\n",
       "         24.416404           0.003000    0.2\n",
       "         49.526814           0.002886    0.2\n",
       "         74.458465           0.002993    0.1\n",
       "         100.000000          0.002644    0.4\n",
       "\n",
       "[598 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_probabilities_df.groupby(['text_idx', 'depth'])\\\n",
    "    [['attention_scores', 'score']]\\\n",
    "    .mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = attention_probabilities_df['score']\n",
    "probas = attention_probabilities_df['attention_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48087500597446187"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(target.astype(int), probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03408837057062263"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.corr(probas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
